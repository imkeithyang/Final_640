---
title: "Exploring Difference in Difference Estimator Behavior Under Different Settings"
author: "Zheyuan Liu, Haoming Yang"
date: "4/16/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(tidyr)
```


```{r}
inverse_logit = function(logit) {
  return (exp(logit)/(1+exp(logit)))
}
```

$$
\begin{gather*}
Y \sim Bernoulli (p) \\
l = \alpha + \gamma G + \delta_t t + \tau D + \beta x + \epsilon \\
p = \frac{e^{l}}{1+e^{l}}
\end{gather*}
$$

```{r}
# Binary Timepoint
t = c(0,1)
# Binaray Treatment
treatment = c(0,1)
n_control = 1000
n_treat = 300
x = list(rnorm(n_control, 0, 1), rnorm(n_treat, 0, 1))

alpha = rnorm(1,0,1)
gamma = rnorm(1,0,1)
delta_t = rnorm(1,0.2,1)
tau = rnorm(1,0.2,1)
beta = rnorm(1,0,1)

error = rnorm(n_control, 0, 0.1)
logit_before_untreat = alpha + gamma*treatment[1] + delta_t*t[1] + 
  tau*t[1]*treatment[1] + beta*x[[1]] + error

error = rnorm(n_treat, 0, 0.1)
logit_before_treat = alpha + gamma*treatment[2] + delta_t*t[1] + 
  tau*t[1]*treatment[2] + beta*x[[2]] + error

error = rnorm(n_control, 0, 0.1)
logit_after_untreat = alpha + gamma*treatment[1] + delta_t*t[2] + 
  tau*t[2]*treatment[1] + beta*x[[1]] + error

error = rnorm(n_treat, 0, 0.1)
logit_after_treat = alpha + gamma*treatment[2] + delta_t*t[2] + 
  tau*t[2]*treatment[2] + beta*x[[2]] + error

logit_after_treat_para = alpha + gamma*treatment[2] + delta_t*t[2] +
  beta*x[[2]] + error

df_logit = data.frame(treatment = c(rep(0, n_control), rep(1, n_treat)),
                      logit_before = c(logit_before_untreat, logit_before_treat),
                      logit_after = c(logit_after_untreat, logit_after_treat))

ggplot(df_logit, aes(x=logit_before, color=factor(treatment))) +
  geom_point(aes(y=logit_after))+ 
  scale_color_manual(values=c("black", "red"))

df_avg_logit = data.frame(t = t,
                          logit_untreat = c(mean(logit_before_untreat), mean(logit_after_untreat)), 
                          logit_treat = c(mean(logit_before_treat), mean(logit_after_treat)),
                          logit_treat_para = c(mean(logit_before_treat), mean(logit_after_treat_para)))
ggplot(df_avg_logit, aes(x = t))+
  geom_line(aes(y=logit_untreat)) + 
  geom_point(aes(y=logit_untreat)) +
  geom_line(aes(y=logit_treat), color="red") + 
  geom_point(aes(y=logit_treat), color="black") + 
  geom_line((aes(y=logit_treat_para)), linetype="dashed", color="red") +
  geom_point(aes(y=logit_treat_para), color="black")
```



```{r}
df_y_logit = data.frame(treatment = c(rep(0, n_control), rep(1, n_treat)),
logit_before = as.integer(inverse_logit(c(logit_before_untreat, logit_before_treat))>0.5),
logit_after = as.integer(inverse_logit(c(logit_after_untreat, logit_after_treat))>0.5))
```


$$
\begin{gather*}
Y \sim Poisson (\lambda) \\
\log(\lambda) = \alpha + \gamma G + \delta_t t + \tau D + \beta x + \epsilon \\
\end{gather*}
$$

To simulate outcome, we take the modeled log lambda and sample from Poisson distribution


```{r}
# Binary Timepoint
t = c(0,1)
# Binaray Treatment
treatment = c(0,1)
n_control = 1000
n_treat = 300
x = list(rnorm(n_control, 0, 1), rnorm(n_treat, 0, 1))

alpha = rnorm(1,0,1)
gamma = rnorm(1,0,1)
delta_t = rnorm(1,0.2,1)
tau = rnorm(1,0.2,1)
beta = rnorm(1,0,1)

error = rnorm(n_control, 0, 0.1)
lambda_before_untreat = alpha + gamma*treatment[1] + delta_t*t[1] + 
  tau*t[1]*treatment[1] + beta*x[[1]] + error

error = rnorm(n_treat, 0, 0.1)
lambda_before_treat = alpha + gamma*treatment[2] + delta_t*t[1] + 
  tau*t[1]*treatment[2] + beta*x[[2]] + error

error = rnorm(n_control, 0, 0.1)
lambda_after_untreat = alpha + gamma*treatment[1] + delta_t*t[2] + 
  tau*t[2]*treatment[1] + beta*x[[1]] + error

error = rnorm(n_treat, 0, 0.1)
lambda_after_treat = alpha + gamma*treatment[2] + delta_t*t[2] + 
  tau*t[2]*treatment[2] + beta*x[[2]] + error

lambda_after_treat_para = alpha + gamma*treatment[2] + delta_t*t[2] +
  beta*x[[2]] + error

df_lambda = data.frame(treatment = c(rep(0, n_control), rep(1, n_treat)),
                      lambda_before = c(lambda_before_untreat, lambda_before_treat),
                      lambda_after = c(lambda_after_untreat, lambda_after_treat))

ggplot(df_lambda, aes(x=lambda_before, color=factor(treatment))) +
  geom_point(aes(y=lambda_after)) + 
  scale_color_manual(values=c("black", "red"))

df_avg_lambda = data.frame(t = t,
                          lambda_untreat = c(mean(lambda_before_untreat), mean(lambda_after_untreat)), 
                          lambda_treat = c(mean(lambda_before_treat), mean(lambda_after_treat)),
                          lambda_treat_para = c(mean(lambda_before_treat), mean(lambda_after_treat_para)))
ggplot(df_avg_lambda, aes(x = t))+
  geom_line(aes(y=lambda_untreat)) + 
  geom_point(aes(y=lambda_untreat)) +
  geom_line(aes(y=lambda_treat), color="red") + 
  geom_point(aes(y=lambda_treat), color="black") + 
  geom_line((aes(y=lambda_treat_para)), linetype="dashed", color="red") +
  geom_point(aes(y=lambda_treat_para), color="black")
```

```{r}
df_y_poisson = data.frame(treatment = c(rep(0, n_control), rep(1, n_treat)),
logit_before = rpois(n_control + n_treat, exp(c(lambda_before_untreat, lambda_before_treat))),
logit_after = rpois(n_control + n_treat, exp(c(lambda_after_untreat, lambda_after_treat))))
```

# non-parametric
```{r}
non_para_did <- function(df){
  y_1_t1 <- mean(df$outcome[df$treatment == 1 & df$time_point == 1])
  y_1_t0 <- mean(df$outcome[df$treatment == 1 & df$time_point == 0])
  
  y_0_t1 <-  mean(df$outcome[df$treatment == 0 & df$time_point == 1])
  y_0_t0 <-  mean(df$outcome[df$treatment == 0 & df$time_point == 0])
  
  did <- (y_1_t1 - y_1_t0) - (y_0_t1 - y_0_t0)
  
  return (did)
}
```


## DiD non parametric
```{r}
df_logit = data.frame(y_before = logit[t==0], 
                      y_after = logit[t==1],
                      treatment = c(rep(0,500), rep(1,500)))
ggplot(df_logit, aes(x=y_before, color=factor(treatment))) + 
  geom_point(aes(y=y_after))

ggplot(df_poisson, aes(x=exp(lambda_projection), color=factor(treatment))) + 
  geom_point(aes(y=exp(lambda)))


DiD(logit_projection, logit, treatment)
DiD(lambda_projection, lambda, treatment)
```

# fitting logistic regression on binary
```{r}
# change dataframe name (df_binary and df_poisson)
logistic_fit <- glm(outcome ~ treatment + time_point + time_point*treatment + x, 
                     data = df_binary, 
                     family = "binomial")



poisson_fit <- glm(outcome ~ treatment + time_point + time_point*treatment + x, 
                     data = df_poisson, 
                     family = "poisson")
```


# Card and Kruger's Parallel Trend Assumption 
```{r, warning = FALSE}

dat <- read_table2('public.dat')
codebook <- read_lines(file = "codebook")

# extract variable name
variable_names <- codebook %>%
  `[`(8:59) %>%
  `[`(-c(5, 6, 13, 14, 32, 33)) %>%
  str_sub(1, 13) %>%
  str_squish() %>%
  str_to_lower()


# match with raw data
dat <- dat %>%
  select(-X47) %>%
  `colnames<-`(., variable_names) %>%
  mutate_all(as.numeric) %>%
  mutate(sheet = as.character(sheet))


# compare before and after outcome
dat <- dat %>% 
  group_by(state) %>% 
  mutate(fte=empft+nmgrs+(0.5*emppt),
         fte_after=empft2+nmgrs2+(0.5*emppt2)) 


summary <- dat %>% group_by(state) %>% 
            summarise(mean_before=mean(fte,na.rm=T),
                      mean_after=mean(fte_after,na.rm=T),
                      var_before=var(fte,na.rm=T),
                      var_after=var(fte_after,na.rm=T),
                      count_before=sum(!is.na(fte)),
                      count_after=sum(!is.na(fte_after))) %>%
           ungroup() %>%
           mutate(se_before=sqrt(var_before/count_before),
                  se_after=sqrt(var_after/count_after)) %>%
          mutate(state=ifelse(state==0,"PA","NJ")) 


# treatment and control average unemployment
plot_df <- dat %>%
  group_by(state) %>% 
  summarise(mean_before=mean(fte,na.rm=T),
            mean_after=mean(fte_after,na.rm=T)) %>%
  mutate(state = ifelse(state == 0, "PA", "NJ")) 

# wide to long format 
plot_df_2 <- gather(plot_df, 
                    time, 
                    obs_unemployment, 
                    mean_before:mean_after, 
                    factor_key = TRUE) 

# impute counterfactual unemployment average on the treated 
y_counterfactual = plot_df_2[3,3] - plot_df_2[1, 3] + plot_df_2[2, 3]

plot_df_2 <- plot_df_2 %>%
  mutate(time = ifelse(time == 'mean_before', 0, 1))

plot_df_2$diff_unemploy <- plot_df_2$obs_unemployment
plot_df_2[4, 4] <- y_counterfactual[1,1]


# plot parallel trend asssumption 
ggplot(plot_df_2) +
  geom_line(aes(x = time, y = obs_unemployment, linetype = state)) +
  geom_line(aes(x = time, y = diff_unemploy, linetype = state)) +
  labs(title = "Minimum Wage Observed Effect and Counterfactual Effect on NJ and PA ")

  
```


# Regression Perspective 
```{r}
dat_regression <- gather(dat, 
                    time, 
                    unemployment, 
                    fte:fte_after, 
                    factor_key = TRUE) 

dat_regression <- dat_regression %>%
  mutate(time = ifelse(time == 'fte', 0, 1)) %>%
  select(state, time, unemployment)

# unparametric did 
colnames(dat_regression) <- c("treatment", "time_point", "outcome")
non_para_did(dat_regression)

# fitting linear regression 
linear_minum_wage <- lm(unemployment ~ state + time + state * time, 
                        data = dat_regression)
summary(linear_minum_wage)
```


